<!doctype html>
<html class="theme-next use-motion ">
<head>
  

<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>


<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>




<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />








  <link rel="stylesheet" type="text/css" href="/others/fancybox/source/jquery.fancybox.css?v=2.1.5"/>






  <link href="/vendors/googleapis/css/Lato.css" rel="stylesheet" type="text/css">




<link rel="stylesheet" type="text/css" href="/others/font-awesome/css/font-awesome.min.css?v=4.4.0" />

<link rel="stylesheet" type="text/css" href="/css/main.css?v=0.4.5.2"/>


    <meta name="description" content="向上，向阳！" />



  <meta name="keywords" content="Machine Learning,Deeping Learning,job," />





  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=0.4.5.2" />


<meta name="description" content="code{white-space: pre;}">
<meta name="keywords" content="Machine Learning,Deeping Learning,job">
<meta property="og:type" content="article">
<meta property="og:title" content="加油！一定能找到好工作！">
<meta property="og:url" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/index.html">
<meta property="og:site_name" content="SmileLingyong">
<meta property="og:description" content="code{white-space: pre;}">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/sigmod_01.png">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/sigmod_02.png">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/tanh_01.png">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/tanh_02.png">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/ReLU_01.png">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/ReLU_02.png">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/Leaky_ReLU_01.png">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/BN.png">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/BN_02.png">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/caffe_conv_02.jpg">
<meta property="og:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/caffe_conv_01.png">
<meta property="og:updated_time" content="2019-05-10T10:33:14.162Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="加油！一定能找到好工作！">
<meta name="twitter:description" content="code{white-space: pre;}">
<meta name="twitter:image" content="http://yoursite.com/2019/05/08/加油！一定能找到好工作！/sigmod_01.png">


<script type="text/javascript" id="hexo.configuration">
  var CONFIG = {
    scheme: '',
    sidebar: 'always'
  };
</script>



  <title> 加油！一定能找到好工作！ | SmileLingyong </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="">

  <!--[if lte IE 8]>
  <div style=' clear: both; height: 59px; padding:0 0 0 15px; position: relative;margin:0 auto;'>
    <a href="http://windows.microsoft.com/en-US/internet-explorer/products/ie/home?ocid=ie6_countdown_bannercode">
      <img src="http://7u2nvr.com1.z0.glb.clouddn.com/picouterie.jpg" border="0" height="42" width="820"
           alt="You are using an outdated browser. For a faster, safer browsing experience, upgrade for free today or use other browser ,like chrome firefox safari."
           style='margin-left:auto;margin-right:auto;display: block;'/>
    </a>
  </div>
<![endif]-->
  






  <div id="container" class="container one-column page-post-detail">

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  
  
    <ul id="menu" class="menu ">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
      
	  	<span style="font-size:14px;float:right;padding:39px 40px 0 0;">——穷则独善其身，达则兼济天下.</span>
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">

        	<div id="content" class="content"> 

  <div id="posts" class="posts-expand">
    

  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                加油！一定能找到好工作！
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            Posted on
            <time itemprop="dateCreated" datetime="2019-05-08T23:18:23+08:00" content="2019-05-08">
              2019-05-08 23:18
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp; In
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                
                  , 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/DL/" itemprop="url" rel="index">
                    <span itemprop="name">DL</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
            <span id="/2019/05/08/加油！一定能找到好工作！/"class="leancloud_visitors"  data-flag-title="加油！一定能找到好工作！">
            &nbsp; | &nbsp;   
            views
            </span>
          
        </div>
      </header>
    


    <div class="post-body">

      
      

      
        <span itemprop="articleBody"><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <meta name="generator" content="pandoc">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pygments-css@1.0.0/github.min.css" type="text/css">
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
</head>
<body>
<a id="more"></a>
<h2 id="模型评估">模型评估</h2>
<h4 id="模型评估常用方法">模型评估常用方法</h4>
<p>一般情况来说，单一评分标准无法完全评估一个机器学习模型。只用good和bad偏离真实场景去评估某个模型，都是一种欠妥的评估方式。下面介绍常用的分类模型和回归模型评估方法。</p>
<p><strong>（1）分类模型常用评估方法：</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">指标</th>
<th>描述</th>
<th>Scikit-learn函数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Precision</td>
<td>精准度</td>
<td>from sklearn.metrics import precision_score</td>
</tr>
<tr class="even">
<td align="left">Recall</td>
<td>召回率</td>
<td>from sklearn.metrics import recall_score</td>
</tr>
<tr class="odd">
<td align="left">F1</td>
<td>F1值</td>
<td>from sklearn.metrics import f1_score</td>
</tr>
<tr class="even">
<td align="left">Confusion Matrix</td>
<td>混淆矩阵</td>
<td>from sklearn.metrics import confusion_matrix</td>
</tr>
<tr class="odd">
<td align="left">ROC</td>
<td>ROC曲线</td>
<td>from sklearn.metrics import roc</td>
</tr>
<tr class="even">
<td align="left">AUC</td>
<td>ROC曲线下的面积</td>
<td>from sklearn.metrics import auc</td>
</tr>
<tr class="odd">
<td align="left">precision</td>
<td>查准率</td>
<td></td>
</tr>
<tr class="even">
<td align="left">recall</td>
<td>查全率</td>
<td></td>
</tr>
<tr class="odd">
<td align="left">P-R曲线</td>
<td>查准率为纵轴，查全率为横轴，作图</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>（2）回归模型常用评估方法：</strong></p>
<table>
<colgroup>
<col width="30%">
<col width="9%">
<col width="61%">
</colgroup>
<thead>
<tr class="header">
<th align="left">指标</th>
<th align="left">描述</th>
<th align="left">Scikit-learn函数</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Mean Square Error (MSE, RMSE)</td>
<td align="left">均方误差</td>
<td align="left">from sklearn.metrics import mean_squared_error</td>
</tr>
<tr class="even">
<td align="left">Absolute Error (MAE, RAE)</td>
<td align="left">绝对误差</td>
<td align="left">from sklearn.metrics import mean_absolute_error, median_absolute_error</td>
</tr>
<tr class="odd">
<td align="left">R-Squared</td>
<td align="left">R平方值</td>
<td align="left">from sklearn.metrics import r2_score</td>
</tr>
</tbody>
</table>
<h4 id="机器学习中的biaserror和variance有什么区别和联系">机器学习中的Bias，Error和Variance有什么区别和联系</h4>
<p>Bias(偏差)，Error(误差)，和Variance(方差)</p>
<p><strong>对于Bias：</strong></p>
<ul>
<li>Bias衡量模型<strong>拟合训练数据的能力</strong> (训练数据不一定是整个 training dataset，而是只用于训练它的那一部分数据，例如：mini-batch)</li>
<li>Bias 越小，拟合能力越高 (可能产生overfitting)；反之，拟合能力越低 (可能产生underfitting)</li>
</ul>
<p><strong>对于Variance：</strong></p>
<ul>
<li>Variance 衡量<strong>模型的泛化的能力</strong></li>
<li>Variance 越小，模型的泛化的能力越高；反之，模型的泛化的能力越低。</li>
</ul>
<blockquote>
<p>训练误差大，测试误差小 → Bias大</p>
<p>训练误差小，测试误差大→ Variance大 → 降VC维</p>
<p>训练误差大，测试误差大→ 升VC维</p>
</blockquote>
<h4 id="经验误差与泛化误差">经验误差与泛化误差</h4>
<p><strong>误差</strong>（error）：一般地，我们把学习器的实际预测输出与样本的真是输出之间的差异称为“误差”</p>
<p><strong>经验误差</strong>（empirical error）：也叫训练误差（training error）。模型在训练集上的误差。</p>
<p><strong>泛化误差</strong>（generalization error）：模型在新样本集（测试集）上的误差称为“泛化误差”。</p>
<h4 id="过拟合与欠拟合">过拟合与欠拟合</h4>
<ul>
<li><strong>欠拟合</strong>指模型不能在<strong>训练集</strong>上获得足够低的<strong>训练误差</strong>；</li>
<li><strong>过拟合</strong>指模型的<strong>训练误差</strong>与<strong>测试误差</strong>（泛化误差）之间差距过大；</li>
<li>反映在<strong>评价指标</strong>上，就是模型在训练集上表现良好，但是在测试集和新数据上表现一般（<strong>泛化能力差</strong>）；</li>
</ul>
<h2 id="激活函数">激活函数</h2>
<h4 id="为什么需要激活函数">为什么需要激活函数？</h4>
<ul>
<li>激活函数对模型学习、理解非常复杂的、和非线性的函数具有重要作用</li>
<li>使用<strong>激活函数</strong>的目的是为了向网络中加入<strong>非线性因素</strong> 。从而加强网络的表示能力，解决<strong>线性模型</strong>无法解决的问题</li>
</ul>
<h4 id="为什么要使用非线性激活函数">为什么要使用非线性激活函数？</h4>
<blockquote>
<p><strong>神经网络的万能近似定理</strong>认为，神经网络具有至少一个非线性隐藏层，那么只要给予网络足够数量的隐藏单元，它就可以以任意的精度来近似任何<strong>从一个有限维空间到另一个有限维空间</strong>的函数。</p>
</blockquote>
<ul>
<li>如果不使用非线性激活函数，那么每一层输出都是上层输入的<strong>线性组合</strong>；此时无论网络有多少层，其整体也将是线性的，就做不到用非线性来逼近任意函数，导致失去万能近似的性质</li>
<li>使用非线性激活函数 ，可以增强网络的表示能力，使它可以学习从输入到输出之间复杂的非线性的映射。而且，仅<strong>部分层是纯线性</strong>是可以接受的，这有助于<strong>减少网络中的参数</strong>。</li>
</ul>
<h4 id="什么时候可以用线性激活函数">什么时候可以用线性激活函数</h4>
<ul>
<li>输出层，大多使用线性激活函数</li>
<li>在隐含层可能会使用一些线性激活函数</li>
<li>一般用到的线性激活函数很少</li>
</ul>
<h4 id="常见的激活函数">常见的激活函数</h4>
<ul>
<li><span class="math inline">\(Sigmoid\)</span></li>
</ul>
<p><span class="math inline">\(Sigmod\)</span> 又叫作 <strong><span class="math inline">\(Logistic\)</span> 激活函数</strong>，它将实数值压缩进 0 到 1 的区间内，还可以在预测概率的输出层中使用。该函数将大的负数转换成 0，将大的正数转换成 1. 数学公式为：<br>
<span class="math display">\[
y = \sigma(x) = \frac{1}{1 + e^{-x}}   \\
y&#39; = y * (1 - y)
\]</span><br>
下图展示了 Sigmoid 函数及其导数：</p>
<div class="figure">
<img src="/2019/05/08/加油！一定能找到好工作！/sigmod_01.png" alt="Sigmoid激活函数">
<p class="caption">Sigmoid激活函数</p>
</div>
<div class="figure">
<img src="/2019/05/08/加油！一定能找到好工作！/sigmod_02.png" alt="Sigmoid激活函数导数">
<p class="caption">Sigmoid激活函数导数</p>
</div>
<ul>
<li><span class="math inline">\(Sigmoid\)</span> 函数的三个主要缺陷：</li>
<li><strong>梯度消失</strong>：Sigmoid 函数在输入取绝对值非常大的正值或负值时会出现 <strong>饱和</strong> 现象，在图像上表现为变得很平缓，此时函数会对输入的微小变化不敏感，即此时的梯度趋近于0，造成梯度消失，网络权重更新缓慢或不更新。</li>
<li><strong>不以零为中心</strong>：Sigmoid 输出不以零为中心的</li>
<li><strong>计算成本高昂</strong>：<span class="math inline">\(exp()\)</span> 函数与其他非线性激活函数相比，计算成本高昂</li>
</ul>
<hr>
<ul>
<li><span class="math inline">\(Tanh\)</span> 函数</li>
</ul>
<p><span class="math inline">\(Tanh\)</span> 函数又叫作<strong>双曲正切激活函数</strong>。与 <span class="math inline">\(Sigmoid\)</span> 函数类似，区别是值域为 <span class="math inline">\((-1, 1)\)</span> ，且 <span class="math inline">\(Tanh\)</span> 函数的输出以零为中心，因为区间在 <span class="math inline">\(-1\)</span> 到 <span class="math inline">\(1\)</span> 之间。</p>
<div class="figure">
<img src="/2019/05/08/加油！一定能找到好工作！/tanh_01.png" alt="Tanh函数">
<p class="caption">Tanh函数</p>
</div>
<div class="figure">
<img src="/2019/05/08/加油！一定能找到好工作！/tanh_02.png" alt="Tanh函数导数">
<p class="caption">Tanh函数导数</p>
</div>
<ul>
<li>缺点：</li>
<li><strong>梯度消失</strong>： <span class="math inline">\(Tanh\)</span> 函数也会有梯度消失的问题，因此在饱和时也会「杀死」梯度。</li>
<li><strong>计算成本高昂</strong>：<span class="math inline">\(exp()\)</span> 函数与其他非线性激活函数相比，计算成本高昂</li>
</ul>
<h4 id="为什么tanh收敛速度比sigmoid快">为什么Tanh收敛速度比Sigmoid快</h4>
<ul>
<li><span class="math inline">\(tanh^{&#39;}(x)=1-tanh(x)^{2}\in (0,1)\)</span></li>
<li><span class="math inline">\(s^{&#39;}(x)=s(x)*(1-s(x))\in (0,\frac{1}{4}]\)</span></li>
</ul>
<p>由上面两个公式可知 <span class="math inline">\(Tanh\)</span> 梯度消失的问题比 <span class="math inline">\(Sigmoid\)</span> 轻，所以 <span class="math inline">\(Tanh\)</span> 收敛速度比 <span class="math inline">\(Sigmoid\)</span> 快。</p>
<hr>
<ul>
<li><span class="math inline">\(Relu\)</span> 函数</li>
</ul>
<p><span class="math inline">\(ReLU\)</span> 是从底部开始半修正的一种函数，数学公式为：<br>
<span class="math display">\[
f(x) = max(0, x)
\]</span><br>
<img src="/2019/05/08/加油！一定能找到好工作！/ReLU_01.png"><br>
<img src="/2019/05/08/加油！一定能找到好工作！/ReLU_02.png"></p>
<ul>
<li>优点：</li>
<li><strong>加速网络训练：</strong>当输入 x &lt; 0 时，输出为 0，当 x &gt; 0 时，输出为 x。该激活函数使网络更快速地收敛。</li>
<li><strong>避免梯度消失</strong>： <span class="math inline">\(ReLU\)</span> 的导数始终是一个常数，负半区为 0，正半区为 1，所以不会发生梯度消失现象。而 <span class="math inline">\(Sigmoid\)</span> 函数在输入取绝对值非常大的正值或负值时会出现<strong>饱和</strong>现象.</li>
<li><strong>减缓过拟合</strong>：<span class="math inline">\(ReLU\)</span> 在负半区的输出为 0。一旦神经元的激活值进入负半区，那么该激活值就不会产生梯度/不会被训练，造成了网络的稀疏性——<strong>稀疏激活</strong> 。这有助于减少参数的相互依赖，缓解过拟合问题的发生</li>
<li><strong>加速计算</strong>：<span class="math inline">\(ReLU\)</span> 的求导不涉及浮点运算，所以速度更快</li>
<li>缺点：</li>
<li><strong>不以零为中心</strong>：和 <span class="math inline">\(Sigmoid\)</span> 激活函数类似，<span class="math inline">\(ReLU\)</span> 函数的输出不以零为中心。</li>
<li>当 x = 0 时，该点的梯度未定义，但是这个问题在实现中得到了解决，通过采用左侧或右侧的梯度的方式 。</li>
</ul>
<hr>
<ul>
<li><span class="math inline">\(Leaky\ ReLU\)</span></li>
</ul>
<p>该函数试图缓解 <code>dead ReLU</code> 问题。数学公式为：<br>
<span class="math display">\[
f(x) = max(0.1x, x)
\]</span><br>
<img src="/2019/05/08/加油！一定能找到好工作！/Leaky_ReLU_01.png"></p>
<p><span class="math inline">\(Leaky\ ReLU\)</span> 的概念是：当 x &lt; 0 时，它得到 0.1 的正梯度。该函数一定程度上缓解了 <code>dead ReLU</code> 问题，但是使用该函数的结果并不连贯。尽管它具备 <span class="math inline">\(ReLU\)</span> 激活函数的所有特征，如计算高效、快速收敛、在正区域内不会饱和。</p>
<p><span class="math inline">\(Leaky\ ReLU\)</span> 可以得到更多扩展。不让 x 乘常数项，而是让 x 乘超参数，这看起来比 <span class="math inline">\(Leaky\ ReLU\)</span> 效果要好。该扩展就是 <span class="math inline">\(Parametric\ ReLU\)</span>。</p>
<hr>
<ul>
<li><span class="math inline">\(Parametric\ ReLU\)</span></li>
</ul>
<p><span class="math display">\[
f(x) = max(ax, x)
\]</span></p>
<p>其中 <span class="math inline">\(\alpha\)</span> 是一个可以学习的参数，因为你可以对它进行反向传播。这使神经元能够选择负区域最好的梯度，有了这种能力，它们可以变成 ReLU 或 Leaky ReLU。</p>
<h4 id="怎样理解-relu-0-时是非线性激活函数">怎样理解 ReLU（&lt; 0 时）是非线性激活函数</h4>
<p>从 <span class="math inline">\(ReLU\)</span> 的图像可以看出具有一下特点：</p>
<ul>
<li>单侧抑制</li>
<li>相对宽阔的兴奋边界</li>
<li>稀疏激活性</li>
</ul>
<p><span class="math inline">\(ReLU\)</span> 函数从图像上看，是一个分段线性函数，把所有的负值都变为 0，而正值不变，这样就成为单侧抑制。因为有了这单侧抑制，才使得神经网络中的神经元也具有了稀疏激活性。</p>
<hr>
<h2 id="bn层作用以及如何使用bn层">BN层作用，以及如何使用BN层</h2>
<p><strong><a href="https://www.cnblogs.com/guoyaohua/p/8724433.html" target="_blank" rel="noopener">BN</a></strong> (Batch Normalization批标准化) 是一种<strong>正则化</strong>方法（减少泛化误差），主要作用有：</p>
<ul>
<li>加速网络的训练</li>
<li>缓解梯度消失</li>
<li>防止过拟合</li>
<li>增强模型的泛化能力</li>
<li>支持更大的学习率</li>
<li>降低了参数初始化的要求</li>
</ul>
<h4 id="动机">动机</h4>
<ul>
<li><strong>训练的本质是学习数据分布</strong>。如果训练数据与测试数据的分布不同会<strong>降低</strong>模型的<strong>泛化能力</strong>。因此，应该在开始训练前对所有输入数据做归一化处理。</li>
<li>而在神经网络中，因为<strong>每个隐层</strong>的参数不同，会使下一层的输入发生变化，从而导致每一批数据的分布也发生改变；<strong>致使</strong>网络在每次迭代中都需要拟合不同的数据分布，增大了网络的训练难度与<strong>过拟合</strong>的风险。</li>
</ul>
<h4 id="基本原理">基本原理</h4>
<p><strong>（1）训练阶段</strong></p>
<ul>
<li>BN 方法会针对<strong>每一批数据</strong>，在<strong>网络的每一层输入</strong>之前增加<strong>归一化</strong>处理，使输入的均值为 <code>0</code>，标准差为 <code>1</code>。<strong>目的</strong>是将数据限制在统一的分布下。</li>
<li>具体来说，针对每层的第 <code>k</code> 个神经元，计算<strong>这一批数据</strong>在第 <code>k</code> 个神经元的均值与标准差，然后将归一化后的值作为该神经元的激活值。</li>
</ul>
<p><span class="math display">\[
\boldsymbol{\hat{x}_{k}} = \frac{\boldsymbol{x_{k}}-\mathrm{E}\left[\boldsymbol{x_{k}}\right]}{\sqrt{\operatorname{Var}\left[\boldsymbol{x_{k}}\right]}}
\]</span></p>
<ul>
<li>BN 可以看作在各层之间加入了一个新的计算层，<strong>对数据分布进行额外的约束</strong>，从而增强模型的泛化能力；</li>
<li>但同时 BN 也降低了模型的拟合能力，破坏了之前学到的<strong>特征分布</strong>；</li>
<li>为了<strong>恢复数据的原始分布</strong>，BN 引入了一个<strong>重构变换</strong>来还原最优的输入数据分布，其中 <code>γ</code> 和 <code>β</code> 是我们要训练学习的参数。</li>
</ul>
<p><span class="math display">\[
\boldsymbol{y_{k}} \leftarrow \gamma \boldsymbol{\hat{x}_{k}}+\beta
\]</span></p>
<p><strong>小结：</strong></p>
<ul>
<li>以上过程可归纳为一个 <strong><code>BN(x)</code> 函数</strong>：</li>
</ul>
<p><span class="math display">\[
\large\begin{aligned}
\large\boldsymbol{y_i}=
\mathrm{BN}(\boldsymbol{x_i})
&amp;=\gamma\boldsymbol{\hat{x}_i} + \beta \\
&amp;=\gamma\frac{\boldsymbol{x_i}-\boldsymbol{\mathrm{E}[x_i]}}{\sqrt{\boldsymbol{\mathrm{Var}[x_i]}+\epsilon}}+\beta\end{aligned}
\]</span></p>
<ul>
<li>完整算法：</li>
</ul>
<div class="figure">
<img src="/2019/05/08/加油！一定能找到好工作！/BN.png">

</div>
<p><strong>（2）测试阶段</strong></p>
<p>测试的时候，每次可能只会传入<strong>单个数据</strong>，此时的均值和标准差，模型会使用<strong>全局统计量</strong>代替<strong>批统计量</strong>；即使用训练时所有batch得到的一组组的均值和方差，计算其数学期望做为全局统计量。<br>
<span class="math display">\[
\begin{array}{c}{\mathrm{E}[x] \leftarrow \mathrm{E}\left[\mu_{i}\right]} \\ {\operatorname{Var}[x] \leftarrow \frac{m}{m-1} \mathrm{E}\left[\sigma_{i}^{2}\right]}\end{array}
\]</span></p>
<blockquote>
<p>其中 <span class="math inline">\(μ_i\)</span> 和 <span class="math inline">\(σ_i\)</span> 分别表示第 <span class="math inline">\(i\)</span> 轮 batch 保存的均值和标准差；<span class="math inline">\(m\)</span> 为 batch_size，系数 <span class="math inline">\(\frac{m}{m-1}\)</span> 用于计算<strong>无偏方差估计</strong> （原文称该方法为<strong>移动平均</strong>（moving averages））</p>
</blockquote>
<p>然后再将按照训练的流程，将输入数据，减去全局统计量均值和标准差，再进行重构变换得到新的数据最为神经元的激活值。</p>
<ul>
<li>此时，<code>BN(x)</code> 调整为：</li>
</ul>
<p><span class="math display">\[
\large\begin{aligned}\mathrm{BN}(\boldsymbol{x_i})&amp;=\gamma\frac{\boldsymbol{x_i}-\boldsymbol{\mathrm{E}[x_i]}}{\sqrt{\boldsymbol{\mathrm{Var}[x_i]} + \epsilon}} + \beta\\&amp;=\frac{\gamma}{\sqrt{\boldsymbol{\mathrm{Var}[x_i]} + \epsilon}}\boldsymbol{x_i} + \left(\beta-\frac{\gamma\boldsymbol{\mathrm{E}[x_i]}}{\sqrt{\boldsymbol{\mathrm{Var}[x_i]} + \epsilon}}\right)\end{aligned}
\]</span></p>
<p>这样写的目的是为了减少计算量，推理阶段公式中的两个分式是固定值，可以预先计算好，这样推理阶段就可以直接使用。</p>
<ul>
<li><strong>完整算法：</strong></li>
</ul>
<div class="figure">
<img src="/2019/05/08/加油！一定能找到好工作！/BN_02.png">

</div>
<ul>
<li><strong>Reference:</strong> <a href="https://www.cnblogs.com/guoyaohua/p/8724433.html" target="_blank" rel="noopener">理解</a> <a href="https://zhuanlan.zhihu.com/p/34879333" target="_blank" rel="noopener">实战</a> <a href="https://www.zhihu.com/question/38102762" target="_blank" rel="noopener">知乎</a></li>
</ul>
<h4 id="为什么训练时不采用移动平均">为什么训练时不采用移动平均？</h4>
<ul>
<li>用 BN 的目的就是为了保证每批数据的分布稳定，使用训练时使用全局统计量反而违背了这个初衷；</li>
<li>BN 的作者认为在训练时采用移动平均可能会与梯度优化存在冲突；</li>
</ul>
<hr>
<h2 id="caffe">Caffe</h2>
<h4 id="caffe卷积层的实现">Caffe卷积层的实现</h4>
<p>Caffe的卷积层实现，使用 <code>im2col</code> 操作，将数据以及卷积核分别转换成新的矩阵，然后将两对矩阵进行内积运算（inner product)。这样做，比原始的卷积操作速度更快。</p>
<div class="figure">
<img src="/2019/05/08/加油！一定能找到好工作！/caffe_conv_02.jpg">

</div>
<p>其中 <code>im2col</code> : 将一个大矩阵，重叠地划分为多个子矩阵，对每个子矩阵序列化成向量，最后得到另外一个矩阵。</p>
<div class="figure">
<img src="/2019/05/08/加油！一定能找到好工作！/caffe_conv_01.png">

</div>
</body>
</html>
</span>
      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Machine-Learning/" rel="tag">#Machine Learning</a>
          
            <a href="/tags/Deeping-Learning/" rel="tag">#Deeping Learning</a>
          
            <a href="/tags/job/" rel="tag">#job</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/05/10/面试准备/" rel="prev">
                <i class="fa fa-chevron-left"></i> 面试准备
              </a>
            
          </div>

          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/29/C-中的set/" rel="next">
                C++中的set <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>

 </div>

        

        
          <div class="comments" id="comments">
            
          </div>
        
      

        
          
  
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
      
      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table Of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview" sidebar-panel >
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" src="/images/avatar.jpg" alt="SmileLingyong" itemprop="image"/>
          <p class="site-author-name" itemprop="name">SmileLingyong</p>
        </div>
        <p class="site-description motion-element" itemprop="description">向上，向阳！</p>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">20</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          <div class="site-state-item site-state-categories">
            <a href="/categories">
              <span class="site-state-item-count">11</span>
              <span class="site-state-item-name">categories</span>
              </a>
          </div>

          <div class="site-state-item site-state-tags">
            <a href="/tags">
              <span class="site-state-item-count">18</span>
              <span class="site-state-item-name">tags</span>
              </a>
          </div>

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="smilelingyong@gmail.com" target="_blank">
                  <i class="fa fa-e-mail"></i> E-Mail
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://github.com/SmileLingyong" target="_blank">
                  <i class="fa fa-github"></i> Github
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://blog.csdn.net/forever__1234" target="_blank">
                  <i class="fa fa-csdn"></i> CSDN
                </a>
              </span>
            
          
        </div>

        
        

        <div class="links-of-author motion-element">
          
        </div>

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel-active">
          <div class="post-toc-indicator-top post-toc-indicator"></div>
          <div class="post-toc">
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#模型评估"><span class="nav-text">模型评估</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#模型评估常用方法"><span class="nav-text">模型评估常用方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#机器学习中的biaserror和variance有什么区别和联系"><span class="nav-text">机器学习中的Bias，Error和Variance有什么区别和联系</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#经验误差与泛化误差"><span class="nav-text">经验误差与泛化误差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#过拟合与欠拟合"><span class="nav-text">过拟合与欠拟合</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#激活函数"><span class="nav-text">激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么需要激活函数"><span class="nav-text">为什么需要激活函数？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么要使用非线性激活函数"><span class="nav-text">为什么要使用非线性激活函数？</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#什么时候可以用线性激活函数"><span class="nav-text">什么时候可以用线性激活函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#常见的激活函数"><span class="nav-text">常见的激活函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么tanh收敛速度比sigmoid快"><span class="nav-text">为什么Tanh收敛速度比Sigmoid快</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#怎样理解-relu-0-时是非线性激活函数"><span class="nav-text">怎样理解 ReLU（&lt; 0 时）是非线性激活函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bn层作用以及如何使用bn层"><span class="nav-text">BN层作用，以及如何使用BN层</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#动机"><span class="nav-text">动机</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#基本原理"><span class="nav-text">基本原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#为什么训练时不采用移动平均"><span class="nav-text">为什么训练时不采用移动平均？</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#caffe"><span class="nav-text">Caffe</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#caffe卷积层的实现"><span class="nav-text">Caffe卷积层的实现</span></a></li></ol></li></ol></li></ol></div>
            
          </div>
          <div class="post-toc-indicator-bottom post-toc-indicator"></div>
        </section>
      

    </div>
  </aside>


        
	  </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner"> <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="icon-next-heart fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SmileLingyong</span>
</div>

<div class="powered-by">
  Powered by <a class="theme-link" href="http://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="#">
    FreeSky
  </a>(Reserved)

  
  <span id="busuanzi_container_site_uv">
     &nbsp; | &nbsp;  用户量: <span id="busuanzi_value_site_uv"></span>
  </span>
  <span id="busuanzi_container_site_pv">
    &nbsp; | &nbsp;  总访问量: <span id="busuanzi_value_site_pv"></span>
  </span>

  
</div>


<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
 </div>
    </footer>

    <div class="back-to-top"></div>
  </div>

  <script type="text/javascript" src="/others/jquery/index.js?v=2.1.3"></script>

  
  
  
    
    

  


  
  
  <script type="text/javascript" src="/others/fancybox/source/jquery.fancybox.pack.js"></script>
  <script type="text/javascript" src="/js/fancy-box.js?v=0.4.5.2"></script>


  <script type="text/javascript" src="/js/helpers.js?v=0.4.5.2"></script>
  

  <script type="text/javascript" src="/others/velocity/velocity.min.js"></script>
  <script type="text/javascript" src="/others/velocity/velocity.ui.min.js"></script>

  <script type="text/javascript" src="/js/motion_global.js?v=0.4.5.2" id="motion.global"></script>




  <script type="text/javascript" src="/js/nav-toggle.js?v=0.4.5.2"></script>
  <script type="text/javascript" src="/others/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  
<script type="text/javascript" src="/js/bootstrap.scrollspy.js?v=0.4.5.2" id="bootstrap.scrollspy.custom"></script>


<script type="text/javascript" id="sidebar.toc.highlight">
  $(document).ready(function () {
    var tocSelector = '.post-toc';
    var $tocSelector = $(tocSelector);
    var activeCurrentSelector = '.active-current';

    $tocSelector
      .on('activate.bs.scrollspy', function () {
        var $currentActiveElement = $(tocSelector + ' .active').last();

        removeCurrentActiveClass();
        $currentActiveElement.addClass('active-current');

        $tocSelector[0].scrollTop = $currentActiveElement.position().top;
      })
      .on('clear.bs.scrollspy', function () {
        removeCurrentActiveClass();
      });

    function removeCurrentActiveClass () {
      $(tocSelector + ' ' + activeCurrentSelector)
        .removeClass(activeCurrentSelector.substring(1));
    }

    function processTOC () {
      getTOCMaxHeight();
      toggleTOCOverflowIndicators();
    }

    function getTOCMaxHeight () {
      var height = $('.sidebar').height() -
                   $tocSelector.position().top -
                   $('.post-toc-indicator-bottom').height();

      $tocSelector.css('height', height);

      return height;
    }

    function toggleTOCOverflowIndicators () {
      tocOverflowIndicator(
        '.post-toc-indicator-top',
        $tocSelector.scrollTop() > 0 ? 'show' : 'hide'
      );

      tocOverflowIndicator(
        '.post-toc-indicator-bottom',
        $tocSelector.scrollTop() >= $tocSelector.find('ol').height() - $tocSelector.height() ? 'hide' : 'show'
      )
    }

    $(document).on('sidebar.motion.complete', function () {
      processTOC();
    });

    $('body').scrollspy({ target: tocSelector });
    $(window).on('resize', function () {
      if ( $('.sidebar').hasClass('sidebar-active') ) {
        processTOC();
      }
    });

    onScroll($tocSelector);

    function onScroll (element) {
      element.on('mousewheel DOMMouseScroll', function (event) {
          var oe = event.originalEvent;
          var delta = oe.wheelDelta || -oe.detail;

          this.scrollTop += ( delta < 0 ? 1 : -1 ) * 30;
          event.preventDefault();

          toggleTOCOverflowIndicators();
      });
    }

    function tocOverflowIndicator (indicator, action) {
      var $indicator = $(indicator);
      var opacity = action === 'show' ? 0.4 : 0;
      $indicator.velocity ?
        $indicator.velocity('stop').velocity({
          opacity: opacity
        }, { duration: 100 }) :
        $indicator.stop().animate({
          opacity: opacity
        }, 100);
    }

  });
</script>

<script type="text/javascript" id="sidebar.nav">
  $(document).ready(function () {
    var html = $('html');
    var TAB_ANIMATE_DURATION = 200;
    var hasVelocity = $.isFunction(html.velocity);

    $('.sidebar-nav li').on('click', function () {
      var item = $(this);
      var activeTabClassName = 'sidebar-nav-active';
      var activePanelClassName = 'sidebar-panel-active';
      if (item.hasClass(activeTabClassName)) {
        return;
      }

      var currentTarget = $('.' + activePanelClassName);
      var target = $('.' + item.data('target'));

      hasVelocity ?
        currentTarget.velocity('transition.slideUpOut', TAB_ANIMATE_DURATION, function () {
          target
            .velocity('stop')
            .velocity('transition.slideDownIn', TAB_ANIMATE_DURATION)
            .addClass(activePanelClassName);
        }) :
        currentTarget.animate({ opacity: 0 }, TAB_ANIMATE_DURATION, function () {
          currentTarget.hide();
          target
            .stop()
            .css({'opacity': 0, 'display': 'block'})
            .animate({ opacity: 1 }, TAB_ANIMATE_DURATION, function () {
              currentTarget.removeClass(activePanelClassName);
              target.addClass(activePanelClassName);
            });
        });

      item.siblings().removeClass(activeTabClassName);
      item.addClass(activeTabClassName);
    });

    $('.post-toc a').on('click', function (e) {
      e.preventDefault();
      var targetSelector = escapeSelector(this.getAttribute('href'));
      var offset = $(targetSelector).offset().top;
      hasVelocity ?
        html.velocity('stop').velocity('scroll', {
          offset: offset  + 'px',
          mobileHA: false
        }) :
        $('html, body').stop().animate({
          scrollTop: offset
        }, 500);
    });

    // Expand sidebar on post detail page by default, when post has a toc.
    var $tocContent = $('.post-toc-content');
    var $aboutContent = $('#posts-about');
    if (isDesktop() && CONFIG.sidebar === 'post') {
      if ($tocContent.length > 0 && $tocContent.html().trim().length > 0 && $aboutContent.length === 0) {
        displaySidebar();
      }
    }
  });
</script>



  <script type="text/javascript">
    $(document).ready(function () {
      if (CONFIG.sidebar === 'always') {
        displaySidebar();
      }
      if (isMobile()) {
        FastClick.attach(document.body);
      }

      motionIntegrator.bootstrap();
    });
  </script>

  
  

  
  

  
  <script type="text/javascript" src="/js/lazyload.js"></script>
  <script type="text/javascript">
    $(function () {
      $("#posts").find('img').lazyload({
        placeholder: "/images/loading.gif",
        effect: "fadeIn"
      });
    });
  </script>
  
     <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
<script>AV.initialize("9QoQXWnRR4zwSFuxRv52kUpi-gzGzoHsz", "zlgcRzgHF7AHu8TKLJUwCAjw");</script>
<script>
function showTime(Counter) {
  var query = new AV.Query(Counter);
  $(".leancloud_visitors").each(function() {
    var url = $(this).attr("id").trim();
    query.equalTo("url", url);
    query.find({
      success: function(results) {
        if (results.length == 0) {
          var content = $(document.getElementById(url)).text() + ': 0';
          $(document.getElementById(url)).text(content);
          return;
        }
        for (var i = 0; i < results.length; i++) {
          var object = results[i];
          var content = $(document.getElementById(url)).text() + ': ' + object.get('time');
          $(document.getElementById(url)).text(content);
        }
      },
      error: function(object, error) {
        console.log("Error: " + error.code + " " + error.message);
      }
    });

  });
}

function addCount(Counter) {
  var Counter = AV.Object.extend("Counter");
  url = $(".leancloud_visitors").attr('id').trim();
  title = $(".leancloud_visitors").attr('data-flag-title').trim();
  var query = new AV.Query(Counter);
  query.equalTo("url", url);
  query.find({
    success: function(results) {
      if (results.length > 0) {
        var counter = results[0];
        counter.fetchWhenSave(true);
        counter.increment("time");
        counter.save(null, {
          success: function(counter) {
            var content = $(document.getElementById(url)).text() + ': ' + counter.get('time');
            $(document.getElementById(url)).text(content);
          },
          error: function(counter, error) {
            console.log('Failed to save Visitor num, with error message: ' + error.message);
          }
        });
      } else {
        var newcounter = new Counter();
        newcounter.set("title", title);
        newcounter.set("url", url);
        newcounter.set("time", 1);
        newcounter.save(null, {
          success: function(newcounter) {
              console.log("newcounter.get('time')="+newcounter.get('time'));
            var content = $(document.getElementById(url)).text() + ': ' + newcounter.get('time');
            $(document.getElementById(url)).text(content);
          },
          error: function(newcounter, error) {
            console.log('Failed to create');
          }
        });
      }
    },
    error: function(error) {
      console.log('Error:' + error.code + " " + error.message);
    }
  });
}
$(function() {
  var Counter = AV.Object.extend("Counter");
  if ($('.leancloud_visitors').length == 1) {
    addCount(Counter);
  } else if ($('.post-title-link').length > 1) {
    showTime(Counter);
  }
}); 
</script>
  
</body>
</html>
